{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.filters import threshold_otsu\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = [\n",
    "            '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D',\n",
    "            'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T',\n",
    "            'U', 'V', 'W', 'X', 'Y', 'Z'\n",
    "        ]\n",
    "\n",
    "def read_training_data(training_directory):\n",
    "    training_data=[]\n",
    "    for each_letter in letters:\n",
    "        for each in range(10):\n",
    "            image_path = os.path.join(training_directory, each_letter, each_letter + '_' + str(each) + '.jpg')\n",
    "            # read each image of each character\n",
    "            img_details = imread(image_path, as_gray=True)\n",
    "            # converts each character image to binary image\n",
    "            binary_image = img_details < threshold_otsu(img_details)\n",
    "            # 20*20 image becomes 1*400\n",
    "            # in machine learning terms that's 400 features\n",
    "            flat_bin_image = binary_image.reshape(-1)\n",
    "            training_data.append([flat_bin_image, each_letter])\n",
    "\n",
    "    return (np.array(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "# training_dataset_dir = os.path.join(current_dir, 'train')\n",
    "print('reading data')\n",
    "training_dataset_dir = './train20X20'\n",
    "training_data = read_training_data(training_dataset_dir)\n",
    "print(training_data.shape)\n",
    "print('reading data completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomizing the data for better training of the model \n",
    "import random \n",
    "random.shuffle(training_data)\n",
    "\n",
    "X=[]\n",
    "y=[]\n",
    "for features, labels in training_data:\n",
    "    X.append(features)\n",
    "    y.append(labels)\n",
    "\n",
    "X=np.array(X)\n",
    "print(X.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing data\n",
    "#encodeing string labels to integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "#print(integer_encoded)\n",
    "labels_encoded=to_categorical(integer_encoded, num_classes=34) #since it is multiclass classification it converts 34 class vectors to binary class matrix\n",
    "#print(labels_encoded)\n",
    "\n",
    "X=X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=======================training model============================')      #keras module used \n",
    "Inp=Input((400,))\n",
    "x=(Dense(300, activation='tanh'))(Inp)\n",
    "x=(Dense(200, activation='tanh'))(x)\n",
    "x=(Dense(100, activation='tanh'))(x)\n",
    "x=(Dense(100, activation='tanh'))(x)\n",
    "x=(Dense(100, activation='tanh'))(x)\n",
    "x=(Dense(100, activation='tanh'))(x)\n",
    "output= (Dense(34, activation='softmax'))(x)\n",
    "\n",
    "model=Model(Inp, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "epochs=30\n",
    "batch_size=20\n",
    "adam=optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, labels_encoded, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
